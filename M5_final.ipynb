{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import math\n",
    "import pickle\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data from files\n",
    "calendar_df = pd.read_csv('calendar.csv')\n",
    "sales_eval_df = pd.read_csv('sales_train_evaluation.csv')\n",
    "prices_df = pd.read_csv('sell_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_3_180_CA_1_evaluation</td>\n",
       "      <td>FOODS_3_180</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 1947 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id      item_id  dept_id cat_id store_id state_id  \\\n",
       "0  FOODS_3_180_CA_1_evaluation  FOODS_3_180  FOODS_3  FOODS     CA_1       CA   \n",
       "\n",
       "   d_1  d_2  d_3  d_4  ...  d_1932  d_1933  d_1934  d_1935  d_1936  d_1937  \\\n",
       "0    0    0    0    0  ...       0       0       1       0       0       1   \n",
       "\n",
       "   d_1938  d_1939  d_1940  d_1941  \n",
       "0       0       0       0       0  \n",
       "\n",
       "[1 rows x 1947 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pt = sales_eval_df.sample(random_state=42)\n",
    "data_pt = data_pt.reset_index(drop=True)\n",
    "data_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_func_1(X):\n",
    "    #here we are inserting the columns for the days d_1942 to d_1969 as nan for which we need to forecast sales\n",
    "    for i in range(1942,1970):\n",
    "        X['d_'+str(i)] = np.nan\n",
    "        X['d_'+str(i)] = X['d_'+str(i)].astype(np.float16)\n",
    "    \n",
    "    #to transform the dataframe into vertical rows as each corresponds to each day sales of an item from a particular store\n",
    "    X_melt = pd.melt(X, id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],\n",
    "                       var_name='d',value_name='sales')\n",
    "    #creating a single dataframe\n",
    "    X_melt = X_melt.merge(calendar_df,  on='d', how='left')\n",
    "    X_melt = X_melt.merge(prices_df, on=['store_id','item_id','wm_yr_wk'], how='left')\n",
    "    \n",
    "    #pre processing missing values of prices by transforming with mean price of that id\n",
    "    X_melt['sell_price'].fillna(X_melt.groupby('id')['sell_price'].transform('mean'),inplace=True)\n",
    "    \n",
    "    #creating lag features such that the for a product on current day it gets it's sales upto 3 months prior.\n",
    "    shifting = 28 #shift period in order to account for 28 days to forecast\n",
    "    for i in range(9): #num of weeks to shift here 8 weeks we consider\n",
    "        X_melt['lag_'+str(shifting+(7*i))] = X_melt.groupby('id')['sales'].shift(shifting+(7*i)).astype(np.float16)\n",
    "    \n",
    "    #creating constant shift rolling agg features\n",
    "    for i in [7,14,28,35,60]:\n",
    "        X_melt['rolling_mean_'+str(i)] =  X_melt.groupby(['id'])['lag_28'].transform(lambda x: x.rolling(i).mean())\n",
    "        X_melt['rolling_median_'+str(i)] =  X_melt.groupby(['id'])['lag_28'].transform(lambda x: x.rolling(i).median())\n",
    "        \n",
    "    #calender features\n",
    "    X_melt['date'] = pd.to_datetime(X_melt['date'])\n",
    "    #each day of the month\n",
    "    X_melt['day_of_month'] = X_melt['date'].dt.day.astype(np.int8)\n",
    "    #changing year value as 0 for 2011 and 1 for 2012 .... 5 for 2016\n",
    "    X_melt['year'] = (X_melt['year'] - X_melt['year'].min()).astype(np.int8)\n",
    "    #week number of a day in a month ex: 29th in January corresponds to 5th week of January\n",
    "    X_melt['week_no_inmonth'] = X_melt['day_of_month'].apply(lambda x: math.ceil(x/7)).astype(np.int8)\n",
    "    #checking if the day is weekend or not\n",
    "    X_melt['is_weekend'] = (X_melt['wday']<=2).astype(np.int8)\n",
    "    \n",
    "    #changing the dtype to category for these columns in order to process the columns with label encoding\n",
    "    cat_cols = ['id','item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2','snap_CA','snap_TX','snap_WI']\n",
    "    lenc = LabelEncoder()\n",
    "    for col in cat_cols:\n",
    "        X_melt[col] = X_melt[col].astype('category')\n",
    "        #preprocessing the categorical columns into label encoded columns\n",
    "        X_melt[col] = lenc.fit_transform(X_melt[col].astype(str))\n",
    "    #splitting the values of 'd' comlumn to take only the day number    \n",
    "    X_melt['d'] = X_melt['d'].apply(lambda x: x.split('_')[1]).astype(np.int16)\n",
    "    #final dataframe after pre-processing and feature engineering we are taking last 2 years historical sales\n",
    "    X_melt = X_melt.loc[pd.to_datetime(X_melt['date'].dt.date) >= '2014-01-02']\n",
    "    \n",
    "    X_pre = X_melt.drop(['sales','date','weekday','wm_yr_wk'],axis=1)\n",
    "    X_pre.reset_index(drop=True,inplace=True)\n",
    "    n_rows = int(len(X_pre)*0.2)\n",
    "    X_pre  = X_pre.tail(n_rows)\n",
    "    N = 18\n",
    "    X_pre_pred = pd.DataFrame()\n",
    "    predictions_df = pd.DataFrame()\n",
    "    best_base_models = ['M'+str(i) for i in range(1,N+1)]\n",
    "    preds_X_pre  = ['pred_'+str(i) for i in range(int(X_pre.iloc[0]['d']),int(X_pre.iloc[-1]['d'])+1)]\n",
    "    features_X_pre_pred = ['X_fea_'+str(i) for i in range(1,N+1)]\n",
    "    #N represents number of base models\n",
    "    for i in tqdm(range(N)):\n",
    "        #predicting for all the days of X_pre using trained N base models and using them as features\n",
    "        preds_X_pre[i] = pd.DataFrame()\n",
    "        file_name = best_base_models[i]+'.pkl'\n",
    "        for k in range(int(X_pre.iloc[0]['d']),int(X_pre.iloc[-1]['d'])+1):\n",
    "            best_base_models[i] = joblib.load(file_name)\n",
    "            best_base_models[i].n_jobs = -1\n",
    "            preds_X_pre[i]['d_'+str(k)] = best_base_models[i].predict(X_pre[X_pre['d']==k])\n",
    "        df1 = pd.melt(preds_X_pre[i],var_name='d',value_name='sales')\n",
    "        X_pre_pred[features_X_pre_pred[i]] = df1['sales'].values\n",
    "    best_metaM = joblib.load('best_meta_model.pkl')\n",
    "    best_metaM.n_jobs = -1\n",
    "    predictions = best_metaM.predict(X_pre_pred.values)\n",
    "    #slicing the predictions such that to get each day predictions of all the products of test data\n",
    "    start = 0\n",
    "    t = int(X_pre.iloc[0]['d'])\n",
    "    while start < len(predictions):\n",
    "        end = start + 1\n",
    "        predictions_df['d_'+str(t)] = predictions[start:end]\n",
    "        start = end\n",
    "        t = t+1\n",
    "    predictions_df = pd.concat([X['id'],predictions_df],axis=1,sort=False)\n",
    "    predictions_df_val = predictions_df[['id']]\n",
    "    #validation predictions from days 1914-1941\n",
    "    for i in range(28):\n",
    "        predictions_df_val['F'+str(i+1)] = predictions_df['d_'+str(1914+i)]\n",
    "    predictions_df_val['id'] =  predictions_df_val['id'].apply(lambda x: x.replace('evaluation','validation'))\n",
    "    predictions_df_eval = predictions_df_val.copy()\n",
    "    #evaluation predictions from days 1942-1969\n",
    "    for i in range(28):\n",
    "        predictions_df_eval['F'+str(i+1)] = predictions_df['d_'+str(1942+i)]\n",
    "    predictions_df_eval[\"id\"] = predictions_df_eval[\"id\"].apply(lambda x: x.replace('validation','evaluation'))\n",
    "    final_predictions = predictions_df_val.append(predictions_df_eval).reset_index(drop=True)\n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [09:20<00:00, 31.11s/it]\n"
     ]
    }
   ],
   "source": [
    "forecasted_sales = final_func_1(data_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast sales from days 1914 till 1941 is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_3_180_CA_1_validation</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id   F1   F2   F3   F4   F5   F6   F7   F8   F9  \\\n",
       "0  FOODS_3_180_CA_1_validation 0.58 0.52 0.51 0.44 0.47 0.60 0.58 0.43 0.41   \n",
       "\n",
       "   ...  F19  F20  F21  F22  F23  F24  F25  F26  F27  F28  \n",
       "0  ... 0.39 0.44 0.49 0.49 0.44 0.44 0.43 0.43 0.54 0.52  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Forecast sales from days 1914 till 1941 is:')\n",
    "forecasted_sales.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast sales from days 1942 till 1969 is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_3_180_CA_1_evaluation</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id   F1   F2   F3   F4   F5   F6   F7   F8   F9  \\\n",
       "1  FOODS_3_180_CA_1_evaluation 0.43 0.40 0.46 0.40 0.49 0.53 0.67 0.45 0.48   \n",
       "\n",
       "   ...  F19  F20  F21  F22  F23  F24  F25  F26  F27  F28  \n",
       "1  ... 0.49 0.61 0.63 0.48 0.47 0.50 0.45 0.47 0.57 0.55  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Forecast sales from days 1942 till 1969 is:')\n",
    "forecasted_sales.iloc[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_func_2(X,y):\n",
    "    #here we are inserting the columns for the days d_1914 to d_1941 as nan for which we need to forecast sales\n",
    "    for i in range(1914,1942):\n",
    "        X['d_'+str(i)] = np.nan\n",
    "        X['d_'+str(i)] = X['d_'+str(i)].astype(np.float16)\n",
    "    \n",
    "    #to transform the dataframe into vertical rows as each corresponds to each day sales of an item from a particular store\n",
    "    X_melt = pd.melt(X, id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],\n",
    "                       var_name='d',value_name='sales')\n",
    "    #creating a single dataframe\n",
    "    X_melt = X_melt.merge(calendar_df,  on='d', how='left')\n",
    "    X_melt = X_melt.merge(prices_df, on=['store_id','item_id','wm_yr_wk'], how='left')\n",
    "    \n",
    "    #pre processing missing values of prices by transforming with mean price of that id\n",
    "    X_melt['sell_price'].fillna(X_melt.groupby('id')['sell_price'].transform('mean'),inplace=True)\n",
    "    \n",
    "    #creating lag features such that the for a product on current day it gets it's sales upto 3 months prior.\n",
    "    shifting = 28 #shift period in order to account for 28 days to forecast\n",
    "    for i in range(9): #num of weeks to shift here 8 weeks we consider\n",
    "        X_melt['lag_'+str(shifting+(7*i))] = X_melt.groupby('id')['sales'].shift(shifting+(7*i)).astype(np.float16)\n",
    "    \n",
    "    #creating constant shift rolling agg features\n",
    "    for i in [7,14,28,35,60]:\n",
    "        X_melt['rolling_mean_'+str(i)] =  X_melt.groupby(['id'])['lag_28'].transform(lambda x: x.rolling(i).mean())\n",
    "        X_melt['rolling_median_'+str(i)] =  X_melt.groupby(['id'])['lag_28'].transform(lambda x: x.rolling(i).median())\n",
    "        \n",
    "    #calender features\n",
    "    X_melt['date'] = pd.to_datetime(X_melt['date'])\n",
    "    #each day of the month\n",
    "    X_melt['day_of_month'] = X_melt['date'].dt.day.astype(np.int8)\n",
    "    #changing year value as 0 for 2011 and 1 for 2012 .... 5 for 2016\n",
    "    X_melt['year'] = (X_melt['year'] - X_melt['year'].min()).astype(np.int8)\n",
    "    #week number of a day in a month ex: 29th in January corresponds to 5th week of January\n",
    "    X_melt['week_no_inmonth'] = X_melt['day_of_month'].apply(lambda x: math.ceil(x/7)).astype(np.int8)\n",
    "    #checking if the day is weekend or not\n",
    "    X_melt['is_weekend'] = (X_melt['wday']<=2).astype(np.int8)\n",
    "    \n",
    "    #changing the dtype to category for these columns in order to process the columns with label encoding\n",
    "    cat_cols = ['id','item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2','snap_CA','snap_TX','snap_WI']\n",
    "    lenc = LabelEncoder()\n",
    "    for col in cat_cols:\n",
    "        X_melt[col] = X_melt[col].astype('category')\n",
    "        #preprocessing the categorical columns into label encoded columns\n",
    "        X_melt[col] = lenc.fit_transform(X_melt[col].astype(str))\n",
    "    #splitting the values of 'd' comlumn to take only the day number    \n",
    "    X_melt['d'] = X_melt['d'].apply(lambda x: x.split('_')[1]).astype(np.int16)\n",
    "    #final dataframe after pre-processing and feature engineering we are taking last 2 years historical sales\n",
    "    X_melt = X_melt.loc[pd.to_datetime(X_melt['date'].dt.date) >= '2014-01-02']\n",
    "    \n",
    "    X_pre = X_melt.drop(['sales','date','weekday','wm_yr_wk'],axis=1)\n",
    "    X_pre.reset_index(drop=True,inplace=True)\n",
    "    n_rows = int(len(X_pre)*0.2)\n",
    "    X_pre  = X_pre.tail(n_rows)\n",
    "    N = 18\n",
    "    X_pre_pred = pd.DataFrame()\n",
    "    predictions_df = pd.DataFrame()\n",
    "    best_base_models = ['M'+str(i) for i in range(1,N+1)]\n",
    "    preds_X_pre  = ['pred_'+str(i) for i in range(int(X_pre.iloc[0]['d']),int(X_pre.iloc[-1]['d'])+1)]\n",
    "    features_X_pre_pred = ['X_fea_'+str(i) for i in range(1,N+1)]\n",
    "    #N represents number of base models\n",
    "    for i in tqdm(range(N)):\n",
    "        #predicting for all the days of X_pre using trained N base models and using them as features\n",
    "        preds_X_pre[i] = pd.DataFrame()\n",
    "        file_name = best_base_models[i]+'.pkl'\n",
    "        for k in range(int(X_pre.iloc[0]['d']),int(X_pre.iloc[-1]['d'])+1):\n",
    "            best_base_models[i] = joblib.load(file_name)\n",
    "            best_base_models[i].n_jobs = -1\n",
    "            preds_X_pre[i]['d_'+str(k)] = best_base_models[i].predict(X_pre[X_pre['d']==k])\n",
    "        df1 = pd.melt(preds_X_pre[i],var_name='d',value_name='sales')\n",
    "        X_pre_pred[features_X_pre_pred[i]] = df1['sales'].values\n",
    "    best_metaM = joblib.load('best_meta_model.pkl')\n",
    "    best_metaM.n_jobs = -1\n",
    "    predictions = best_metaM.predict(X_pre_pred.values)\n",
    "    #slicing the predictions such that to get each day predictions of all the products of test data\n",
    "    start = 0\n",
    "    t = int(X_pre.iloc[0]['d'])\n",
    "    while start < len(predictions):\n",
    "        end = start + 1\n",
    "        predictions_df['d_'+str(t)] = predictions[start:end]\n",
    "        start = end\n",
    "        t = t+1\n",
    "    predictions_df = pd.concat([X['id'],predictions_df],axis=1,sort=False)\n",
    "    predictions_df_val = predictions_df[['id']]\n",
    "    #validation predictions from days 1914-1941\n",
    "    for i in range(28):\n",
    "        predictions_df_val['F'+str(i+1)] = predictions_df['d_'+str(1914+i)]\n",
    "    predictions_df_val['id'] =  predictions_df_val['id'].apply(lambda x: x.replace('evaluation','validation'))\n",
    "    \n",
    "    df = X.loc[:,'d_1070':'d_1941']\n",
    "    train_df = df.iloc[:,:-28]\n",
    "    scale_lst = []\n",
    "    for i in range(len(train_df)):\n",
    "        val = train_df.iloc[i].values\n",
    "        # to consider the periods following the first non-zero demand observed for the series under evaluation.\n",
    "        val = val[np.argmax(val!=0):]\n",
    "        #to scale the squared-error as taking the consecutive difference of each day sales\n",
    "        scale = ((val[1:] - val[:-1]) ** 2).mean()\n",
    "        #storing the scale value corresponding to each time series\n",
    "        scale_lst.append(scale)\n",
    "    scale_arr = np.array(scale_lst)\n",
    "    predictions_df_val.drop(['id'],inplace=True,axis=1)\n",
    "    predictions_df_val.columns = ['d_'+str(1914+i) for i in range(28)]\n",
    "    #computing mean squared error\n",
    "    num = ((predictions_df_val - y)**2).mean(axis=1)\n",
    "    #scaled error i.e., root mean squared scaled error\n",
    "    rmsse = (num/scale_arr).map(np.sqrt)\n",
    "    #since we have a single time series the weight in WRMSSE is 1\n",
    "    w_i = 1\n",
    "    WRMSSE = w_i*rmsse\n",
    "    return WRMSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [08:42<00:00, 29.03s/it]\n"
     ]
    }
   ],
   "source": [
    "WRMSSE = final_func_2(data_pt.iloc[:,:-28],data_pt.iloc[:,-28:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluated error metric WRMSSE is:  0.775\n"
     ]
    }
   ],
   "source": [
    "print('The evaluated error metric WRMSSE is: ',round(np.float(WRMSSE.values),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
